# 字幕翻译功能使用指南

## 功能简介

字幕翻译功能是基于原有的字幕检测技术，结合大语言模型（LLM）翻译能力，实现视频字幕的自动翻译。与传统的字幕去除（inpainting）相比，翻译模式具有以下优势：

- ✅ **保持画质**：无需 AI 修复，避免画质损失
- ✅ **提供翻译**：实际翻译字幕内容，而非简单删除
- ✅ **速度更快**：无需 inpainting，处理速度更快
- ✅ **可定制化**：支持多种目标语言和样式配置

## 工作原理

```
┌─────────────────────────────────────────────────────────────┐
│  1. 字幕检测 (PaddleOCR)                                      │
│     - 使用 DB 算法检测文字框                                   │
│     - 过滤非字幕区域（保留底部、长条形文字）                     │
└─────────────────────────────────────────────────────────────┘
                          ↓
┌─────────────────────────────────────────────────────────────┐
│  2. OCR 识别                                                 │
│     - 使用 PaddleOCR 识别每个字幕框的文字                       │
│     - 建立 {帧号: [字幕1, 字幕2, ...]} 映射                    │
└─────────────────────────────────────────────────────────────┘
                          ↓
┌─────────────────────────────────────────────────────────────┐
│  3. 智能分段                                                  │
│     - 合并重复字幕（去重）                                     │
│     - 按 ~2000 字符分段                                       │
│     - 保持句子完整性（不截断句子）                              │
└─────────────────────────────────────────────────────────────┘
                          ↓
┌─────────────────────────────────────────────────────────────┐
│  4. LLM 翻译 (Ollama API)                                    │
│     - 每段调用大模型翻译                                       │
│     - 使用 JSON 格式输出（原文→译文映射）                       │
│     - Temperature=0.3 保证翻译稳定性                          │
└─────────────────────────────────────────────────────────────┘
                          ↓
┌─────────────────────────────────────────────────────────────┐
│  5. 字幕渲染                                                  │
│     - 使用黑/白底色覆盖原字幕                                   │
│     - 使用 PIL 渲染翻译后的文字                                │
│     - 自动字体大小和居中对齐                                   │
└─────────────────────────────────────────────────────────────┘
```

## 使用方法

### 1. 准备工作

#### 获取 API Key

翻译功能需要调用 Ollama API，您需要先获取 API Key。

- **API 地址**：https://ollama.iamdev.cn
- **API Key**：请联系管理员获取

#### 启动 Web 服务

```bash
cd /ssd/github/video-subtitle-remover
git pull  # 拉取最新代码

# 启动服务
cd web
./start-dev.sh
```

### 2. 使用 Web 界面

访问 http://your-server:5173

#### 步骤 1：上传视频

1. 拖拽或点击上传视频文件
2. 等待上传完成

#### 步骤 2：选择翻译模式

1. 在"处理模式"中选择 **"翻译字幕"**
2. 配置翻译参数：

**必填项：**
- **API Key**：输入您的 Ollama API Key

**可选项：**
- **目标语言**：选择翻译目标语言
  - 中文（默认）
  - English
  - 日本語
  - 한국어
  - Español
  - Français

- **字幕底色**：选择覆盖原字幕的背景颜色
  - 黑色（默认，适合浅色背景）
  - 白色（适合深色背景）

- **API 地址**：默认 https://ollama.iamdev.cn（可自定义）

- **模型**：默认 gpt-oss:20b（可自定义）

- **字幕区域**：可选，手动指定字幕区域坐标
  - 格式：[ymin, ymax, xmin, xmax]
  - 示例：[880, 1080, 0, 1920]（1080p 视频底部 200px）

#### 步骤 3：开始翻译

1. 点击 **"开始翻译"** 按钮
2. 等待处理完成（实时进度显示）
3. 下载翻译后的视频

## 配置说明

### 字幕区域过滤

翻译功能会自动过滤非字幕区域，保留符合以下条件的文字：

1. **位置**：位于画面下半部分（Y > 画面高度 * 0.5）
2. **宽高比**：宽度 > 高度 * 3（扁平形状）
3. **宽度**：宽度 > 画面宽度 * 0.2（占一定比例）

这样可以避免将画面中的其他文字（如 logo、标题等）误认为字幕。

### 智能分段规则

为了保证翻译质量，系统会将字幕智能分段：

1. **分段大小**：每段约 2000 字符
2. **句子完整性**：不会在句子中间截断
3. **示例**：
   ```
   如果第 2000 个字符在某一帧的字幕中间（该帧字幕到第 2003 个字符结束）
   那么分段点会设在第 2003 个字符之后，保持该帧字幕完整
   ```

### API 调用参数

翻译 API 请求示例：

```json
{
  "model": "gpt-oss:20b",
  "messages": [
    {
      "role": "system",
      "content": "你是一个专业的字幕翻译助手，擅长将字幕翻译成中文。"
    },
    {
      "role": "user",
      "content": "请将以下字幕翻译成中文。要求：\n1. 保持原意，符合中文表达习惯\n2. 输出JSON格式，key为原文，value为译文\n3. 不要添加任何解释或额外内容\n\n字幕列表：\n[\"Hello world\", \"How are you\"]\n\n请只返回JSON对象..."
    }
  ],
  "response_format": {"type": "json_object"},
  "temperature": 0.3
}
```

响应示例：

```json
{
  "Hello world": "你好世界",
  "How are you": "你好吗"
}
```

## 字幕渲染

### 字体选择

系统会自动检测并使用系统字体：

| 系统 | 默认字体路径 |
|------|------------|
| macOS | `/System/Library/Fonts/PingFang.ttc` |
| Linux | `/usr/share/fonts/truetype/wqy/wqy-microhei.ttc` |
| Windows | `C:\Windows\Fonts\msyh.ttc` |

如果找不到系统字体，会使用 PIL 默认字体。

### 渲染效果

- **背景**：纯色矩形（黑色或白色）覆盖原字幕
- **文字**：自动大小（高度的 60%），居中对齐
- **颜色**：
  - 黑底白字（默认）
  - 白底黑字

## 性能说明

### 处理时间估算

以 1080p、5 分钟视频为例：

| 阶段 | 时间 | 说明 |
|------|------|------|
| 字幕检测 | 1-2 分钟 | 取决于帧数 |
| OCR 识别 | 2-3 分钟 | 取决于字幕数量 |
| LLM 翻译 | 1-5 分钟 | 取决于字幕总量和 API 速度 |
| 字幕渲染 | 1-2 分钟 | 取决于帧数 |
| **总计** | **5-12 分钟** | 比 inpainting 快 50% |

### 进度显示

- **0-50%**：字幕检测和 OCR 识别
- **50-100%**：LLM 翻译和字幕渲染

## 常见问题

### Q1: 翻译失败，提示 API Key 错误

**原因**：API Key 无效或过期
**解决**：检查 API Key 是否正确，联系管理员获取新的 Key

### Q2: 检测到非字幕区域的文字

**原因**：画面中的其他文字（logo、标题等）被误识别
**解决**：手动指定字幕区域坐标，限定识别范围

### Q3: 翻译质量不好

**原因**：
- OCR 识别错误
- LLM 翻译不准确

**解决**：
- 确保视频清晰度足够高
- 尝试不同的目标语言描述
- 调整 API 模型（使用更强大的模型）

### Q4: 渲染的字幕位置不对

**原因**：字体大小或对齐计算问题
**解决**：检查源代码 `render_subtitle` 函数，可能需要调整字体大小系数（当前为 0.6）

### Q5: 处理速度太慢

**原因**：
- OCR 识别慢
- LLM API 响应慢

**解决**：
- 减少视频分辨率
- 使用更快的 LLM 模型
- 指定字幕区域减少识别范围

### Q6: 字幕丢失或不完整

**原因**：字幕区域过滤太严格
**解决**：
- 调整 `is_subtitle_region` 函数的阈值
- 手动指定字幕区域

## 对比：翻译 vs 去除

| 特性 | 翻译模式 | 去除模式 (Inpainting) |
|------|---------|---------------------|
| **画质** | ✅ 保持原画质 | ⚠️ 可能降低画质 |
| **速度** | ✅ 较快（5-12分钟） | ⚠️ 较慢（10-20分钟） |
| **功能** | ✅ 提供翻译 | ❌ 仅删除 |
| **显存** | ✅ 低（仅 OCR） | ⚠️ 高（AI 模型） |
| **依赖** | API Key | GPU/CPU |
| **成本** | 💰 API 调用费用 | 💻 计算资源 |
| **适用场景** | 需要翻译的视频 | 纯粹去除字幕 |

## API 费用

使用 Ollama API 需要付费，费用取决于：

- **Token 数量**：字幕总长度
- **模型选择**：不同模型价格不同
- **调用次数**：分段数量

估算：
- 5 分钟视频约 200-500 个字幕
- 分 1-3 段翻译
- 成本约 0.1-0.5 元（具体以实际为准）

## 技术细节

### 依赖库

Python 后端：
```python
paddleocr  # OCR 识别
Pillow     # 字幕渲染
requests   # API 调用
cv2        # 视频处理
```

前端：
- Vue 3
- Element Plus
- Axios

### 关键代码路径

- 后端服务：`web/server/services/translation_service.py`
- API 路由：`web/server/api/translate.py`
- 前端组件：`web/frontend/src/components/ConfigPanel.vue`
- API 客户端：`web/frontend/src/api/client.js`

### 自定义修改

#### 调整字幕过滤规则

修改 `is_subtitle_region` 函数：

```python
def is_subtitle_region(self, box, frame_height, frame_width):
    xmin, xmax, ymin, ymax = box
    width = xmax - xmin
    height = ymax - ymin

    # 调整宽高比阈值（当前 3，可改为 2.5 或 4）
    if width < height * 3:
        return False

    # 调整位置阈值（当前 0.5，可改为 0.6 或 0.7）
    if ymin < frame_height * 0.5:
        return False

    # 调整宽度阈值（当前 0.2，可改为 0.15 或 0.25）
    if width < frame_width * 0.2:
        return False

    return True
```

#### 调整分段大小

修改 `smart_segment` 调用：

```python
# 默认 2000 字符
segments = self.smart_segment(unique_subtitles, max_chars=2000)

# 改为 1500 字符（更多段，更频繁调用 API）
segments = self.smart_segment(unique_subtitles, max_chars=1500)

# 改为 3000 字符（更少段，单次翻译更多）
segments = self.smart_segment(unique_subtitles, max_chars=3000)
```

#### 调整字体大小

修改 `render_subtitle` 函数：

```python
# 默认 60% 高度
font_size = int(height * 0.6)

# 改为 70% 高度（更大字体）
font_size = int(height * 0.7)

# 改为 50% 高度（更小字体）
font_size = int(height * 0.5)
```

## 更新日志

### v1.0.0 (2026-02-07)
- ✅ 初始版本发布
- ✅ 支持字幕翻译功能
- ✅ 集成 Ollama API
- ✅ 智能分段和去重
- ✅ 自动字幕区域过滤
- ✅ Web 界面集成

## 反馈与贡献

如有问题或建议，请提交 Issue：
https://github.com/YaoFANGUK/video-subtitle-remover/issues

---

**祝您使用愉快！** 🎉
